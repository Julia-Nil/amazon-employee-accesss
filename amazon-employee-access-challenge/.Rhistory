library(vroom)
library(lubridate)
library(tidyverse)
install.packages("discrim")
library(vroom)
library(lubridate)
library(tidyverse)
library(tidymodels)
library(recipes)
library(embed)
library(dials)
library(kknn)
library(discrim)
amazontrain <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv")
amazontrain <- amazontrain %>% mutate(ACTION = factor(ACTION))
amazontest <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/test.csv")
id_cols <- c("RESOURCE","MGR_ID","ROLE_ROLLUP_1","ROLE_ROLLUP_2",
"ROLE_DEPTNAME","ROLE_TITLE","ROLE_FAMILY_DESC",
"ROLE_FAMILY","ROLE_CODE")
amazontrain <- amazontrain %>% mutate(across(all_of(id_cols), as.factor))
amazontest  <- amazontest  %>% mutate(across(all_of(id_cols), as.factor))
amazontrain <- amazontrain %>%
mutate_if(is.character, as.factor) %>%   # convert text to factors
mutate_if(is.numeric, as.factor)         # convert IDs to factors if they’re really categories
amazonrecipetrain <- recipe(ACTION ~ ., data = amazontrain) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_unknown(all_nominal_predictors()) %>%        # handles unseen test levels
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
amazon_nb_model <- naive_Bayes(Laplace=tune(), smoothness=tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes")
nb_wf <- workflow() %>%
add_recipe(amazonrecipetrain) %>%
add_model(amazon_nb_model)
final_wf <- nb_wf %>%
fit(data=amazontrain)
install.packages("naivebayes")
final_wf <- nb_wf %>%
fit(data=amazontrain)
folds <- vfold_cv(amazontrain, v=5)
tuning_grid <- grid_regular(penalty(), mixture(), levels=5)
CV_results <- tune_grid(
amazon_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
folds <- vfold_cv(amazontrain, v=5)
tuning_grid <- grid_regular(Laplace(), smoothness(), levels=5)
CV_results <- tune_grid(
nb_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
best_params <- select_best(CV_results, metric="roc_auc")
final_wf <- nb_wf %>%
finalize_workflow(best_params) %>%
fit(data=amazontrain)
preds <- predict(final_wf, new_data=amazontest, type = "prob") %>%
rename(ACTION=.pred_1)
results <- tibble(id = amazontest$id, ACTION = preds$ACTION)
vroom_write(results,
"C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/knnresults.csv",
delim = ",")
results <- tibble(id = amazontest$id, ACTION = preds$ACTION)
vroom_write(results,
"C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/nbresults.csv",
delim = ",")
install.packages(c("keras", "reticulate"))
library(vroom)
library(lubridate)
library(tidyverse)
library(tidymodels)
library(recipes)
library(embed)
library(dials)
library(kknn)
library(discrim)
library(reticulate)
library(keras)
amazontrain <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv")
amazontrain <- amazontrain %>% mutate(ACTION = factor(ACTION))
amazontest <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/test.csv")
id_cols <- c("RESOURCE","MGR_ID","ROLE_ROLLUP_1","ROLE_ROLLUP_2",
"ROLE_DEPTNAME","ROLE_TITLE","ROLE_FAMILY_DESC",
"ROLE_FAMILY","ROLE_CODE")
amazontrain <- amazontrain %>% mutate(across(all_of(id_cols), as.factor))
amazontest  <- amazontest  %>% mutate(across(all_of(id_cols), as.factor))
amazontrain <- amazontrain %>%
mutate_if(is.character, as.factor) %>%   # convert text to factors
mutate_if(is.numeric, as.factor)         # convert IDs to factors if they’re really categories
NNrecipe <- recipe(ACTION ~ ., data = amazontrain) %>%
update_role(id, new_role="id")
colnames
colnames()
names()
names(amazontrain)
id_cols <- c("RESOURCE","MGR_ID","ROLE_ROLLUP_1","ROLE_ROLLUP_2",
"ROLE_DEPTNAME","ROLE_TITLE","ROLE_FAMILY_DESC",
"ROLE_FAMILY","ROLE_CODE")
amazontrain <- amazontrain %>% mutate(across(all_of(id_cols), as.factor))
amazontest  <- amazontest  %>% mutate(across(all_of(id_cols), as.factor))
amazontrain <- amazontrain %>%
mutate_if(is.character, as.factor) %>%   # convert text to factors
mutate_if(is.numeric, as.factor)         # convert IDs to factors if they’re really categories
NNrecipe <- recipe(ACTION ~ ., data = amazontrain) %>%
update_role(ROLE_CODE, new_role="id")
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_unknown(all_nominal_predictors()) %>%        # handles unseen test levels
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
id_cols <- c("RESOURCE","MGR_ID","ROLE_ROLLUP_1","ROLE_ROLLUP_2",
"ROLE_DEPTNAME","ROLE_TITLE","ROLE_FAMILY_DESC",
"ROLE_FAMILY","ROLE_CODE")
amazontrain <- amazontrain %>% mutate(across(all_of(id_cols), as.factor))
amazontest  <- amazontest  %>% mutate(across(all_of(id_cols), as.factor))
amazontrain <- amazontrain %>%
mutate_if(is.character, as.factor) %>%   # convert text to factors
mutate_if(is.numeric, as.factor)         # convert IDs to factors if they’re really categories
NNrecipe <- recipe(ACTION ~ ., data = amazontrain) %>%
update_role(ROLE_CODE, new_role = "id") %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_unknown(all_nominal_predictors()) %>%        # handles unseen test levels
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>%
step_range(all_numeric_predictors(), min = 0, max = 1)
amazon_nn_model <- mlp(hidden_units=tune(),
epochs=50) %>%
set_engine("keras") %>%
set_mode("classification")
nn_tunegrid <- grid_regular(hidden_units(range=c(1,maxHiddenUnits)),
levels=2)
maxHiddenUnits <- 10   # or however many you want to try
nn_tunegrid <- grid_regular(
hidden_units(range = c(1, maxHiddenUnits)),
levels = 2
)
nn_tunegrid <- grid_regular(hidden_units(range=c(1,maxHiddenUnits)),
levels=2)
nn_wf <- workflow() %>%
add_recipe(NNrecipe) %>%
add_model(amazon_nn_model)
folds <- vfold_cv(amazontrain, v=5)
tuning_grid <- grid_regular(Laplace(), smoothness(), levels=5)
CV_results <- tune_grid(
nn_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
folds <- vfold_cv(amazontrain, v=5)
tuning_grid <- grid_regular(hidden_units(), penalty(), levels = 5)
CV_results <- tune_grid(
nn_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
nn_model <-
mlp(hidden_units = tune(), penalty = tune()) %>%
set_engine("nnet") %>%
set_mode("classification")
maxHiddenUnits <- 10   # or however many you want to try
nn_tunegrid <- grid_regular(
hidden_units(range = c(1, maxHiddenUnits)),
levels = 2
)
nn_tunegrid <- grid_regular(hidden_units(range=c(1,maxHiddenUnits)),
levels=2)
nn_wf <- workflow() %>%
add_recipe(NNrecipe) %>%
add_model(amazon_nn_model)
folds <- vfold_cv(amazontrain, v=5)
tuning_grid <- grid_regular(hidden_units(), penalty(), levels = 5)
CV_results <- tune_grid(
nn_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
folds <- vfold_cv(amazontrain, v = 5)
tuning_grid <- grid_regular(hidden_units(), penalty(), levels = 5)
CV_results <- tune_grid(
nn_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
library(vroom)
library(lubridate)
library(tidyverse)
library(tidymodels)
library(recipes)
library(embed)
library(dials)
library(kknn)
library(discrim)
library(reticulate)
library(keras)
amazontrain <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv")
amazontrain <- amazontrain %>% mutate(ACTION = factor(ACTION))
amazontest <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/test.csv")
id_cols <- c("RESOURCE","MGR_ID","ROLE_ROLLUP_1","ROLE_ROLLUP_2",
"ROLE_DEPTNAME","ROLE_TITLE","ROLE_FAMILY_DESC",
"ROLE_FAMILY","ROLE_CODE")
amazontrain <- amazontrain %>% mutate(across(all_of(id_cols), as.factor))
amazontest  <- amazontest  %>% mutate(across(all_of(id_cols), as.factor))
amazontrain <- amazontrain %>%
mutate_if(is.character, as.factor) %>%   # convert text to factors
mutate_if(is.numeric, as.factor)         # convert IDs to factors if they’re really categories
NNrecipe <- recipe(ACTION ~ ., data = amazontrain) %>%
update_role(ROLE_CODE, new_role = "id") %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_unknown(all_nominal_predictors()) %>%        # handles unseen test levels
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>%
step_range(all_numeric_predictors(), min = 0, max = 1)
nn_model <-
mlp(hidden_units = tune(), penalty = tune()) %>%
set_engine("nnet") %>%
set_mode("classification")
maxHiddenUnits <- 10   # or however many you want to try
nn_tunegrid <- grid_regular(
hidden_units(range = c(1, maxHiddenUnits)),
levels = 2
)
nn_tunegrid <- grid_regular(hidden_units(range=c(1,maxHiddenUnits)),
levels=2)
nn_wf <- workflow() %>%
add_model(nn_model) %>%
add_recipe(NNrecipe)
folds <- vfold_cv(amazontrain, v = 5)
tuning_grid <- grid_regular(hidden_units(), penalty(), levels = 5)
CV_results <- tune_grid(
nn_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
best_params <- select_best(CV_results, metric = "roc_auc")
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv") %>%
mutate(ACTION=factor(ACTION))
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv") %>% mutate(ACTION=factor(ACTION))
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv")
library(vroom)
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv") %>% mutate(ACTION=factor(ACTION))
library(vroom)
library(vroom)
library(tidyverse)
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv")
%>% mutate(ACTION=factor(ACTION))
library(vroom)
library(tidyverse)
library(tidymodels)
train <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/train.csv") %>%
mutate(ACTION=factor(ACTION))
test <- vroom("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge/test.csv")
folds <- vfold_cv(train, v=10)
metSet <- metric_set(roc_auc)
amazonRecipe <- recipe(ACTION~., data=train) %>%
step_mutate_at(all_numeric_predictors(), fn=factor) %>%
step_other(all_nominal_predictors(), threshold = 0.001) %>%
step_dummy(all_nominal_predictors())
logReg_model <- logistic_reg() %>%
set_engine("glm")
system.time({logReg_wf <- workflow() %>%
add_recipe(amazonRecipe) %>%
add_model(logReg_model) %>%
fit(data=train)})
logRegPreds <- logReg_wf %>%
predict(new_data=test, type="prob") %>%
bind_cols(test) %>%
rename(ACTION=.pred_1) %>%
select(id, ACTION)
vroom_write(x=logRegPreds, file="./LogRegwrf.csv", delim=",")
library(vroom)
library(lubridate)
library(tidymodels)
library(recipes)
library(embed)
library(dials)
library(parallel)
library(doParallel)
library(tune)
amazontrain <- vroom("train.csv") %>%
mutate(ACTION = factor(ACTION))
setwd("C:/Users/julia/OneDrive - Brigham Young University/Desktop/stat 348/amazon-employee-access/amazon-employee-access-challenge")
amazontrain <- vroom("train.csv") %>%
mutate(ACTION = factor(ACTION))
amazontest  <- vroom("test.csv")
amazonrecipetrain <- recipe(ACTION ~ ., data = amazontrain) %>%
step_string2factor(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = "ACTION") %>%
step_normalize(all_numeric_predictors())
juice(pre(amazonrecipetrain))
juice(prep(amazonrecipetrain))
amazon_log_model <- rand_forest(
mtry = tune(),
min_n = tune(),
trees = 200
) %>%
set_engine("ranger") %>%
set_mode("classification")
amazon_wf <- workflow() %>%
add_recipe(amazonrecipetrain) %>%
add_model(amazon_log_model)
folds <- vfold_cv(amazontrain, v = 10) # higher is maybe better but slow 10ish
tune_params <- extract_parameter_set_dials(amazon_wf)
tune_params
tune_params <- tune_params %>%
finalize(amazontrain)
tuning_grid <- grid_regular(tune_params, levels = 10)
tuning_grid
tuning_grid <- grid_regular(tune_params, levels = 5)
CV_results <- tune_grid(
amazon_wf,
resamples = folds,
grid = tuning_grid,
metrics = metric_set(roc_auc)
)
tune_params <- extract_parameter_set_dials(amazon_wf)
tune_params <- tune_params %>%
finalize(amazontrain)
tune_params
?finalize
tune_params <- extract_parameter_set_dials(amazon_wf)
tune_params
amazon_log_model <- rand_forest(
mtry = tune(), # 1
min_n = tune(), # 2
trees = 200
) %>%
set_engine("ranger") %>%
set_mode("classification")
amazon_wf <- workflow() %>%
add_recipe(amazonrecipetrain) %>%
add_model(amazon_log_model) %>%
fit(amazontrain)
amazon_log_model <- rand_forest(
mtry = 1, # 1
min_n = 2, # 2
trees = 200
) %>%
set_engine("ranger") %>%
set_mode("classification")
amazon_wf <- workflow() %>%
add_recipe(amazonrecipetrain) %>%
add_model(amazon_log_model) %>%
fit(amazontrain)
preds <- predict(amazon_wf, new_data=amazontest, type = "prob") %>%
rename(ACTION=.pred_1)
# --- Save results ---
results <- tibble(id = amazontest$id, ACTION = preds$ACTION)
results
vroom_write(results, "rfoptresults.csv", delim = ",")
